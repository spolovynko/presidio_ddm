{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from itertools import zip_longest\n",
    "import re\n",
    "\n",
    "file_path = r\"C:\\Users\\spolo\\OneDrive\\Documents\\DOC\\Work\\TCS\\Code\\dynamic_data_masking\\presidio_ddm\\deny_list_dataset\\deny_list_tokens_ddm.xlsx\"\n",
    "new_file_path = r\"C:\\Users\\spolo\\OneDrive\\Documents\\DOC\\Work\\TCS\\Code\\dynamic_data_masking\\presidio_ddm\\deny_list_dataset\\deny_list_tokens_c4_v1.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=\"SEX\")\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "french_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sexual_Orientation</th>\n",
       "      <th>Gender_Identity</th>\n",
       "      <th>Sexual_Anatomy</th>\n",
       "      <th>Sexual_Acts</th>\n",
       "      <th>Sexual_Relationships</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orientation sexuelle</td>\n",
       "      <td>Identité de genre</td>\n",
       "      <td>Anatomie sexuelle</td>\n",
       "      <td>Acte sexuel</td>\n",
       "      <td>Relation sexuelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identité sexuelle</td>\n",
       "      <td>Expression de genre</td>\n",
       "      <td>Organes génitaux</td>\n",
       "      <td>Rapport sexuel</td>\n",
       "      <td>Relation amoureuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hétérosexualité</td>\n",
       "      <td>Sexe assigné à la naissance</td>\n",
       "      <td>Appareil reproducteur</td>\n",
       "      <td>Relation sexuelle</td>\n",
       "      <td>Relation intime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hétérosexuel</td>\n",
       "      <td>Cisgenre</td>\n",
       "      <td>Appareil génital</td>\n",
       "      <td>Coït</td>\n",
       "      <td>Relation passionnelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hétérosexuelle</td>\n",
       "      <td>Cisgenre homme</td>\n",
       "      <td>Anatomie intime</td>\n",
       "      <td>Préliminaires</td>\n",
       "      <td>Relation affective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Pan-sensualité</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Multi-sensualité</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Sensuspectre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Identité multigenre et sexualité</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Autodétermination sexuelle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sexual_Orientation              Gender_Identity  \\\n",
       "0                Orientation sexuelle            Identité de genre   \n",
       "1                   Identité sexuelle          Expression de genre   \n",
       "2                     Hétérosexualité  Sexe assigné à la naissance   \n",
       "3                        Hétérosexuel                     Cisgenre   \n",
       "4                      Hétérosexuelle               Cisgenre homme   \n",
       "..                                ...                          ...   \n",
       "339                    Pan-sensualité                          NaN   \n",
       "340                  Multi-sensualité                          NaN   \n",
       "341                      Sensuspectre                          NaN   \n",
       "342  Identité multigenre et sexualité                          NaN   \n",
       "343        Autodétermination sexuelle                          NaN   \n",
       "\n",
       "            Sexual_Anatomy        Sexual_Acts   Sexual_Relationships  \n",
       "0        Anatomie sexuelle        Acte sexuel      Relation sexuelle  \n",
       "1         Organes génitaux     Rapport sexuel     Relation amoureuse  \n",
       "2    Appareil reproducteur  Relation sexuelle        Relation intime  \n",
       "3         Appareil génital               Coït  Relation passionnelle  \n",
       "4          Anatomie intime      Préliminaires     Relation affective  \n",
       "..                     ...                ...                    ...  \n",
       "339                    NaN                NaN                    NaN  \n",
       "340                    NaN                NaN                    NaN  \n",
       "341                    NaN                NaN                    NaN  \n",
       "342                    NaN                NaN                    NaN  \n",
       "343                    NaN                NaN                    NaN  \n",
       "\n",
       "[344 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "pd.set_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 47\u001b[0m\n\u001b[0;32m     42\u001b[0m     new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(new_df_columns)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[1;32m---> 47\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43maugmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrench_stopwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(new_file_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, if_sheet_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     50\u001b[0m     new_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEX\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m, in \u001b[0;36maugmentation\u001b[1;34m(df, french_stopwords)\u001b[0m\n\u001b[0;32m      8\u001b[0m new_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df[col]\u001b[38;5;241m.\u001b[39mdropna())  \u001b[38;5;66;03m# Remove NaN values\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Split words by space\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m new_column_split \u001b[38;5;241m=\u001b[39m [\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m new_column]\n\u001b[0;32m     12\u001b[0m new_column_split_joined \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m lst \u001b[38;5;129;01min\u001b[39;00m new_column_split \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m lst]\n\u001b[0;32m     13\u001b[0m new_column\u001b[38;5;241m.\u001b[39mextend(new_column_split_joined)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import zip_longest\n",
    "\n",
    "def augmentation(df, french_stopwords):\n",
    "    new_df_columns = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        new_column = list(df[col].dropna())  # Remove NaN values\n",
    "\n",
    "        # Split words by space\n",
    "        new_column_split = [conv.split() for conv in new_column]\n",
    "        new_column_split_joined = [item for lst in new_column_split for item in lst]\n",
    "        new_column.extend(new_column_split_joined)\n",
    "\n",
    "        # Remove French stopwords\n",
    "        new_column = [word for word in new_column if word.lower() not in french_stopwords]\n",
    "\n",
    "        # Handle hyphenated words\n",
    "        split = [sub.split(\"-\") for sub in new_column if '-' in sub]\n",
    "        new_subcat = [item for lst in split for item in lst]\n",
    "        new_column.extend(new_subcat)\n",
    "\n",
    "        # Lowercase transformation\n",
    "        new_column_lower = [word.lower() for word in new_column]\n",
    "        new_column.extend(new_column_lower)\n",
    "\n",
    "        # Remove stopwords again after modifications\n",
    "        new_column = [word for word in new_column if word.lower() not in french_stopwords]\n",
    "\n",
    "        # Convert to unique sorted list\n",
    "        new_column = sorted(set(new_column))\n",
    "\n",
    "        # Store results in dictionary (column_name: column_values)\n",
    "        new_df_columns[col] = new_column\n",
    "\n",
    "    # Make all columns the same length using zip_longest\n",
    "    max_length = max(len(v) for v in new_df_columns.values())\n",
    "    for col in new_df_columns:\n",
    "        new_df_columns[col] += [None] * (max_length - len(new_df_columns[col]))  # Padding with None\n",
    "\n",
    "    # Convert dictionary to DataFrame\n",
    "    new_df = pd.DataFrame(new_df_columns)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "new_df = augmentation(df, french_stopwords)\n",
    "\n",
    "with pd.ExcelWriter(new_file_path, mode='a', if_sheet_exists='new', engine='openpyxl') as writer:\n",
    "    new_df.to_excel(writer, sheet_name='SEX', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexual_Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conviction = list(health[\"Sexual_Orientation\"].dropna())\n",
    "conviction_split  = [conv.split() for conv in conviction]\n",
    "conviction_split_joined = [item for lst in conviction_split for item  in lst]\n",
    "conviction.extend(conviction_split_joined)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "split = [sub.split(\"-\") for sub in conviction if '-' in sub]\n",
    "new_subcat = [item for lst in split for item in lst]\n",
    "conviction.extend(new_subcat)\n",
    "\n",
    "conviction_lower = [word.lower() for word in conviction]\n",
    "conviction.extend(conviction_lower)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "conviction = set(conviction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender_Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conviction = list(health[\"Gender_Identity\"].dropna())\n",
    "conviction_split  = [conv.split() for conv in conviction]\n",
    "conviction_split_joined = [item for lst in conviction_split for item  in lst]\n",
    "conviction.extend(conviction_split_joined)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "split = [sub.split(\"-\") for sub in conviction if '-' in sub]\n",
    "new_subcat = [item for lst in split for item in lst]\n",
    "conviction.extend(new_subcat)\n",
    "\n",
    "conviction_lower = [word.lower() for word in conviction]\n",
    "conviction.extend(conviction_lower)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "conviction = set(conviction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexual_Anatomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conviction = list(health[\"Sexual_Anatomy\"].dropna())\n",
    "conviction_split  = [conv.split() for conv in conviction]\n",
    "conviction_split_joined = [item for lst in conviction_split for item  in lst]\n",
    "conviction.extend(conviction_split_joined)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "split = [sub.split(\"-\") for sub in conviction if '-' in sub]\n",
    "new_subcat = [item for lst in split for item in lst]\n",
    "conviction.extend(new_subcat)\n",
    "\n",
    "conviction_lower = [word.lower() for word in conviction]\n",
    "conviction.extend(conviction_lower)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "conviction = set(conviction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexual_Acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conviction = list(health[\"Sexual_Anatomy\"].dropna())\n",
    "conviction_split  = [conv.split() for conv in conviction]\n",
    "conviction_split_joined = [item for lst in conviction_split for item  in lst]\n",
    "conviction.extend(conviction_split_joined)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "split = [sub.split(\"-\") for sub in conviction if '-' in sub]\n",
    "new_subcat = [item for lst in split for item in lst]\n",
    "conviction.extend(new_subcat)\n",
    "\n",
    "conviction_lower = [word.lower() for word in conviction]\n",
    "conviction.extend(conviction_lower)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "conviction = set(conviction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sexual_Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conviction = list(health[\"Sexual_Relationships\"].dropna())\n",
    "conviction_split  = [conv.split() for conv in conviction]\n",
    "conviction_split_joined = [item for lst in conviction_split for item  in lst]\n",
    "conviction.extend(conviction_split_joined)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "split = [sub.split(\"-\") for sub in conviction if '-' in sub]\n",
    "new_subcat = [item for lst in split for item in lst]\n",
    "conviction.extend(new_subcat)\n",
    "\n",
    "conviction_lower = [word.lower() for word in conviction]\n",
    "conviction.extend(conviction_lower)\n",
    "\n",
    "conviction = [word for word in  conviction if word not in french_stopwords]\n",
    "conviction = set(conviction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
